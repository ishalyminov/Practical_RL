{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_reinforce.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishalyminov/Practical_RL/blob/coursera/week5_policy_based/practice_reinforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-NJKlNONFMn",
        "colab_type": "text"
      },
      "source": [
        "# REINFORCE in TensorFlow\n",
        "\n",
        "Just like we did before for q-learning, this time we'll design a neural network to learn `CartPole-v0` via policy gradient (REINFORCE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TguxNohINRVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94fdc2e3-7662-4ebb-baa1-b64d3ff5f539"
      },
      "source": [
        "! wget https://github.com/ishalyminov/Practical_RL/raw/coursera/setup_google_colab.py -O setup_google_colab.py\n",
        "! pip install gym==0.14.0\n",
        "! apt-get update\n",
        "! apt-get install -y xvfb\n",
        "! wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb -O ../xvfb\n",
        "! apt-get install -y python-opengl ffmpeg\n",
        "! pip install pyglet==1.2.4\n",
        "\n",
        "from setup_google_colab import setup_week5\n",
        "setup_week5()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-04 22:00:19--  https://github.com/ishalyminov/Practical_RL/raw/coursera/setup_google_colab.py\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ishalyminov/Practical_RL/coursera/setup_google_colab.py [following]\n",
            "--2020-04-04 22:00:19--  https://raw.githubusercontent.com/ishalyminov/Practical_RL/coursera/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1744 (1.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   1.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-04 22:00:19 (238 MB/s) - ‘setup_google_colab.py’ saved [1744/1744]\n",
            "\n",
            "Collecting gym==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/75/9e841bc2bc75128e0b65c3d5255d0bd16becb9d8f7120b965d41b8e70041/gym-0.14.0.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym==0.14.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.14.0) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.14.0) (1.12.0)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 37.6MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c1/49/334e279caa3231255725c8e860fa93e72083567625573421db8875846c14/cloudpickle-1.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.14.0) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.14.0-cp36-none-any.whl size=1637522 sha256=d9189add20727db16543b40632bd4938f121cfaf2c1c64b65801ec81db437974\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/53/f6/c0cd3c9bf953f35c0aee7fa62ea209371e92f5e5cced3245ba\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, cloudpickle, gym\n",
            "  Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: gym 0.17.1\n",
            "    Uninstalling gym-0.17.1:\n",
            "      Successfully uninstalled gym-0.17.1\n",
            "Successfully installed cloudpickle-1.2.2 gym-0.14.0 pyglet-1.3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cloudpickle"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 2,586 B/88.7\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 80.8 kB/88.7 kB 91%] [Connecting to cloud\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Waiting for heade\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rHit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rGet:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to cloud.r-proj\r                                                                               \rGet:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [835 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [37.0 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [870 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [31.7 kB]\n",
            "Get:17 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:18 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,793 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [12.2 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,161 kB]\n",
            "Get:21 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [87.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [50.4 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,367 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4,247 B]\n",
            "Get:25 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [865 kB]\n",
            "Fetched 7,386 kB in 3s (2,287 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.4 [784 kB]\n",
            "Fetched 784 kB in 1s (963 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 133872 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "--2020-04-04 22:00:45--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640 [text/plain]\n",
            "Saving to: ‘../xvfb’\n",
            "\n",
            "../xvfb             100%[===================>]     640  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-04 22:00:46 (141 MB/s) - ‘../xvfb’ saved [640/640]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 1s (689 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 133879 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Collecting pyglet==1.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/c3/300c6f92b21886b0fe42c13f3a39a06c6cb90c9fbb1b71da85fe59091a7d/pyglet-1.2.4-py3-none-any.whl (964kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 3.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.3.2\n",
            "    Uninstalling pyglet-1.3.2:\n",
            "      Successfully uninstalled pyglet-1.3.2\n",
            "Successfully installed pyglet-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imvj2DrBNFMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "963a3c27-6510-4d5a-c140-9d80ea43f2d3"
      },
      "source": [
        "# This code creates a virtual display to draw game images on. \n",
        "# If you are running locally, just ignore it\n",
        "\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epfizJ3SNFMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b71003ea-7a7a-46d4-f2d8-1573e2c10cdd"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "# gym compatibility: unwrap TimeLimit\n",
        "if hasattr(env, '_max_episode_steps'):\n",
        "    env = env.env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render(\"rgb_array\"))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f950153ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH8G7jLT21Mn8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LBDUjQFNFMv",
        "colab_type": "text"
      },
      "source": [
        "# Building the policy network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuTJvVc3NFMw",
        "colab_type": "text"
      },
      "source": [
        "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
        "\n",
        "For numerical stability, please __do not include the softmax layer into your network architecture__. \n",
        "\n",
        "We'll use softmax or log-softmax where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocpn9ODuNFMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create input variables. We only need <s,a,R> for REINFORCE\n",
        "# states = tf.placeholder('float32', (None,)+state_dim, name=\"states\")\n",
        "# actions = tf.placeholder('int32', name=\"action_ids\")\n",
        "# cumulative_rewards = tf.placeholder('float32', name=\"cumulative_returns\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X_jtrjjNFM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy = tf.keras.models.Sequential()\n",
        "policy.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "policy.add(tf.keras.layers.Dense(n_actions, activation='relu'))\n",
        "\n",
        "# policy = tf.nn.softmax(logits)\n",
        "# log_policy = tf.nn.log_softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNiRKXgweU-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "74df9ece-188d-40ed-9788-909b76268e5a"
      },
      "source": [
        "policy(np.array([env.reset()]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dense_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.00523839, 0.        ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8icaLXbpNFM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility function to pick action in one given state\n",
        "def get_action_proba(s): \n",
        "    return tf.nn.softmax(policy(np.array([s]))).numpy()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNxU9DyfHa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feed61d4-04bb-4eae-82c3-45c9f82d87f9"
      },
      "source": [
        "get_action_proba(env.reset())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5, 0.5], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbN59Zf-NFM7",
        "colab_type": "text"
      },
      "source": [
        "#### Loss function and updates\n",
        "\n",
        "We now need to define objective and update over policy gradient.\n",
        "\n",
        "Our objective function is\n",
        "\n",
        "$$ J \\approx  { 1 \\over N } \\sum  _{s_i,a_i} \\pi_\\theta (a_i | s_i) \\cdot G(s_i,a_i) $$\n",
        "\n",
        "\n",
        "Following the REINFORCE algorithm, we can define our objective as follows: \n",
        "\n",
        "$$ \\hat J \\approx { 1 \\over N } \\sum  _{s_i,a_i} log \\pi_\\theta (a_i | s_i) \\cdot G(s_i,a_i) $$\n",
        "\n",
        "When you compute gradient of that function over network weights $ \\theta $, it will become exactly the policy gradient.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHYqQcepNFNI",
        "colab_type": "text"
      },
      "source": [
        "### Computing cumulative rewards"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_khUtxaNFNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cumulative_rewards(rewards,    # rewards at each step\n",
        "                           gamma=0.99  # discount for reward\n",
        "                           ):\n",
        "    \"\"\"\n",
        "    take a list of immediate rewards r(s,a) for the whole session \n",
        "    compute cumulative rewards R(s,a) (a.k.a. G(s,a) in Sutton '16)\n",
        "    R_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    The simple way to compute cumulative rewards is to iterate from last to first time tick\n",
        "    and compute R_t = r_t + gamma*R_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "\n",
        "    R_t = []\n",
        "    r_future = 0\n",
        "    for r_t in rewards[::-1]:\n",
        "      r_future = r_future * gamma + r_t\n",
        "      R_t.append(r_future)\n",
        "    R_t = list(reversed(R_t))\n",
        "    return R_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvSh__hlNFNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e342c8d8-1cea-49c8-b307-4136af1449a8"
      },
      "source": [
        "assert len(get_cumulative_rewards(range(100))) == 100\n",
        "assert np.allclose(get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
        "                   [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
        "assert np.allclose(get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
        "                   [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
        "assert np.allclose(get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
        "                   [0, 0, 1, 2, 3, 4, 0])\n",
        "print(\"looks good!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0f4wIl4NFNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "\n",
        "def train_step(_states, _actions, _rewards):\n",
        "    \"\"\"given full session, trains agent with policy gradient\"\"\"\n",
        "    _cumulative_rewards = get_cumulative_rewards(_rewards)\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = policy(np.array(_states))\n",
        "      policy_probs = tf.nn.softmax(logits, axis=-1)\n",
        "      policy_logprobs = tf.nn.log_softmax(logits, axis=-1)\n",
        "      indices = tf.stack([tf.range(tf.shape(policy_logprobs)[0]), _actions], axis=-1)\n",
        "      log_policy_for_actions = tf.gather_nd(policy_logprobs, indices)\n",
        "      policy_for_actions = tf.gather_nd(policy_probs, indices)\n",
        "\n",
        "      J = tf.reduce_mean(tf.math.multiply(log_policy_for_actions, _cumulative_rewards))\n",
        "      entropy = - tf.reduce_mean(tf.math.multiply(log_policy_for_actions, policy_for_actions))\n",
        "      loss = -J - 0.1 * entropy\n",
        "    gradients = tape.gradient(loss, policy.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, policy.trainable_variables)) \n",
        "\n",
        "    #update.run({states: _states, actions: _actions,\n",
        "    #            cumulative_rewards: _cumulative_rewards})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT0wRYG8NFNV",
        "colab_type": "text"
      },
      "source": [
        "### Playing the game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGJKAZwfNFNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_session(env, t_max=1000):\n",
        "    \"\"\"play env with REINFORCE agent and train at the session end\"\"\"\n",
        "\n",
        "    # arrays to record session\n",
        "    states, actions, rewards = [], [], []\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "\n",
        "        # action probabilities array aka pi(a|s)\n",
        "        action_probas = get_action_proba(s)\n",
        "\n",
        "        a = np.random.choice(list(range(action_probas.shape[-1])), size=1, p=action_probas)[0]\n",
        "\n",
        "        new_s, r, done, info = env.step(a)\n",
        "\n",
        "        # record session history to train later\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    train_step(states, actions, rewards)\n",
        "\n",
        "    # technical: return session rewards to print them later\n",
        "    return sum(rewards)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxajzrFMNFNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2c266959-d2c5-444d-e89f-5fb8c18fc1a5"
      },
      "source": [
        "for i in range(100):\n",
        "\n",
        "    rewards = [generate_session(env) for _ in range(100)]  # generate new sessions\n",
        "\n",
        "    print(\"mean reward:%.3f\" % (np.mean(rewards)))\n",
        "\n",
        "    if np.mean(rewards) > 300:\n",
        "        print(\"You Win!\") # but you can train even further\n",
        "        break"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean reward:26.610\n",
            "mean reward:30.430\n",
            "mean reward:34.550\n",
            "mean reward:40.310\n",
            "mean reward:47.020\n",
            "mean reward:65.660\n",
            "mean reward:85.590\n",
            "mean reward:107.560\n",
            "mean reward:150.610\n",
            "mean reward:179.420\n",
            "mean reward:208.120\n",
            "mean reward:275.300\n",
            "mean reward:270.030\n",
            "mean reward:263.430\n",
            "mean reward:323.230\n",
            "You Win!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYInVTrNFNb",
        "colab_type": "text"
      },
      "source": [
        "### Results & video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a9_BRp0NFNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# record sessions\n",
        "import gym.wrappers\n",
        "monitor_env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True)\n",
        "sessions = [generate_session(monitor_env) for _ in range(100)]\n",
        "monitor_env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1csbcPGNFNe",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/videos/openaigym.video.0.119.video000001.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "1768b4ff-8e3a-4e39-f3bd-5234582bfb6c"
      },
      "source": [
        "# show video\n",
        "from IPython.display import HTML\n",
        "import os\n",
        "\n",
        "video_names = list(\n",
        "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "  <source src=\"./videos/openaigym.video.0.119.video000001.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvP6I4D_NFNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43815a3b-e664-4729-f57b-4991c444141f"
      },
      "source": [
        "from submit import submit_cartpole\n",
        "submit_cartpole(generate_session, 'ishalyminov@gmail.com', 'KTgOZ3lFJOWnUzon')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPasWMLDNFNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# That's all, thank you for your attention!\n",
        "# Not having enough? There's an actor-critic waiting for you in the honor section.\n",
        "# But make sure you've seen the videos first."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}